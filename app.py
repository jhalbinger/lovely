from flask import Flask, request, jsonify
import openai
import os
from dotenv import load_dotenv
import json
from collections import defaultdict, deque
import requests  # Necesario para llamar al microservicio de derivaci√≥n

# === CONFIGURACIONES ===
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
project_id = os.getenv("OPENAI_PROJECT_ID")
organization_id = os.getenv("OPENAI_ORG_ID")

client = openai.OpenAI(
    api_key=api_key,
    project=project_id,
    organization=organization_id
)

app = Flask(__name__)

# === CARGAR TODO EL CONTEXTO UNA SOLA VEZ ===
txt_path = "lovely_taller.txt"
if os.path.exists(txt_path):
    with open(txt_path, "r", encoding="utf-8") as f:
        CONTEXTO_COMPLETO = f.read()
else:
    CONTEXTO_COMPLETO = ""

# Memoria por usuario: √∫ltimas 4 interacciones
historial_conversacion = defaultdict(lambda: deque(maxlen=4))

# Diccionario para marcar usuarios que esperan confirmaci√≥n de contacto humano
esperando_confirmacion = {}

@app.route("/webhook", methods=["POST"])
def responder():
    try:
        datos = request.get_json()
        print("üîé JSON recibido desde WhatsApp/Twilio:")
        print(json.dumps(datos, indent=2))

        mensaje_usuario = datos.get("consulta", "")
        user_id = datos.get("user_id", "anon")
        if not mensaje_usuario:
            return jsonify({"error": "No se recibi√≥ ninguna consulta"}), 400

        # === Si este usuario est√° en modo confirmaci√≥n de derivaci√≥n ===
        if esperando_confirmacion.get(user_id):
            if mensaje_usuario.lower() in ["s√≠", "si", "dale", "ok", "quiero", "confirmo"]:
                # ‚úÖ Derivar la consulta al microservicio
                try:
                    # Tomamos la √∫ltima consulta relevante del historial (antes de la confirmaci√≥n)
                    ultima_consulta = historial_conversacion[user_id][-2][1] if len(historial_conversacion[user_id]) >= 2 else mensaje_usuario

                    resp = requests.post(
                        "https://derivacion-humano.onrender.com/derivar-humano",
                        json={"numero": user_id, "consulta": ultima_consulta}
                    )

                    if resp.status_code == 200:
                        respuesta_llm = "‚úÖ Perfecto, ya avis√© a un asesor para que te contacte en breve."
                    else:
                        print("‚ùå Error Twilio:", resp.text)
                        respuesta_llm = "‚ùå Intent√© derivarte, pero hubo un problema. Pod√©s llamar al 011 6028‚Äë1211 para coordinar directo."
                except Exception as e:
                    print("‚ùå Error al derivar:", e)
                    respuesta_llm = "‚ùå No pude avisar al asesor en este momento. Pod√©s llamar al 011 6028‚Äë1211 para coordinar directo."

                # Ya no est√° esperando confirmaci√≥n
                esperando_confirmacion.pop(user_id, None)
                return jsonify({"respuesta": respuesta_llm})
            else:
                # Si dice "no" o algo distinto, cancelar derivaci√≥n
                esperando_confirmacion.pop(user_id, None)
                return jsonify({"respuesta": "üëå Sin problema, cualquier cosa pod√©s consultarme por ac√° cuando quieras."})

        # === Detectar intenci√≥n de compra en el mensaje ===
        palabras_interes = ["comprar", "coordinar", "quiero", "reservar", "me interesa", "c√≥mo pago", "precio final"]
        if any(palabra in mensaje_usuario.lower() for palabra in palabras_interes):
            # Guardamos la intenci√≥n en historial
            historial_conversacion[user_id].append(("user", mensaje_usuario))

            # Respondemos normal pero agregamos la oferta de contacto humano
            respuesta_llm = (
                "Pod√©s comprar este producto con *hasta 12 cuotas sin inter√©s* y demora de entrega de 35-45 d√≠as h√°biles.\n\n"
                "‚úÖ *¬øQuer√©s que un asesor te contacte para coordinar la compra?* Respond√© *S√≠* para derivarte."
            )

            # Marcamos que este usuario est√° esperando confirmaci√≥n
            esperando_confirmacion[user_id] = True

            return jsonify({"respuesta": respuesta_llm})

        # === Si no es intenci√≥n de compra, flujo normal con OpenAI ===
        # === PROMPT ESPECIAL PARA WHATSAPP ===
        system_prompt = (
            "Sos un asistente virtual de *Lovely Taller Deco* üõãÔ∏è. "
            "Respond√© solo con la informaci√≥n del CONTEXTO, no inventes nada. "
            "\n\n"
            "‚û°Ô∏è **Formato WhatsApp:**\n"
            "- Us√° *un solo asterisco* para resaltar palabras clave (productos, precios, direcciones).\n"
            "- Us√° ‚úÖ para listas y agreg√° SALTOS DE L√çNEA entre frases para que el mensaje no quede en un solo bloque.\n"
            "- Cada 1 o 2 frases, cort√° y pon√© un salto de l√≠nea.\n"
            "- Si hay un link, ponelo solo en una l√≠nea para que WhatsApp muestre la vista previa.\n"
            "- M√°ximo 2 emojis por respuesta.\n"
            "\n"
            "‚û°Ô∏è **Extensi√≥n del mensaje:**\n"
            "- Respuesta breve pero completa, ideal para leer en celular (m√°ximo 4-5 l√≠neas de texto).\n"
            "- Si es una lista, m√°ximo 4-5 √≠tems por respuesta.\n"
            "- Despu√©s de responder, suger√≠ UN solo tema l√≥gico para seguir.\n"
            "\n"
            "‚û°Ô∏è **Comportamiento:**\n"
            "- En la PRIMERA respuesta salud√°: '¬°Hola! üëã *Bienvenido a Lovely Taller Deco* üõãÔ∏è‚ú®' y explic√° brevemente qu√© puede consultar.\n"
            "- En mensajes posteriores NO vuelvas a saludar, respond√© directo.\n"
            "- Si ya diste showroom o ubicaci√≥n en la misma conversaci√≥n, no los repitas salvo que lo pidan.\n"
            "- Si la consulta no est√° en el CONTEXTO, no inventes; invit√° a visitar el showroom üè† o llamar al 011 6028‚Äë1211.\n"
        )

        # === ARMAMOS HISTORIAL ===
        historial = list(historial_conversacion[user_id])
        mensajes_historial = []
        for rol, msg in historial:
            mensajes_historial.append({"role": rol, "content": msg})
        mensajes_historial.append({"role": "user", "content": mensaje_usuario})

        # === CONTEXTO + HISTORIAL ===
        user_prompt = (
            f"CONTEXTO:\n{CONTEXTO_COMPLETO}\n\n"
            "Conversaci√≥n previa:\n\n"
        )
        for rol, msg in historial:
            user_prompt += f"{rol.upper()}: {msg}\n"
        user_prompt += f"\nUSUARIO (nuevo): {mensaje_usuario}"

        # === LLAMADA AL MODELO ===
        respuesta = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        )

        respuesta_llm = respuesta.choices[0].message.content.strip()

        # === GUARDAMOS EN HISTORIAL ===
        historial_conversacion[user_id].append(("user", mensaje_usuario))
        historial_conversacion[user_id].append(("bot", respuesta_llm))

        return jsonify({"respuesta": respuesta_llm})

    except Exception as e:
        print("üí• Error detectado:", e)
        return jsonify({"respuesta": "Estoy tardando en procesar tu consulta, intent√° de nuevo en unos segundos üôè"}), 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
