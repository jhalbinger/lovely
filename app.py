from flask import Flask, request, jsonify
import openai
import os
from dotenv import load_dotenv
import json
from collections import defaultdict, deque

# === CONFIGURACIONES ===
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
project_id = os.getenv("OPENAI_PROJECT_ID")
organization_id = os.getenv("OPENAI_ORG_ID")

client = openai.OpenAI(
    api_key=api_key,
    project=project_id,
    organization=organization_id
)

app = Flask(__name__)

# === CARGAR TODO EL CONTEXTO UNA SOLA VEZ ===
txt_path = "lovely_taller.txt"
if os.path.exists(txt_path):
    with open(txt_path, "r", encoding="utf-8") as f:
        CONTEXTO_COMPLETO = f.read()
else:
    CONTEXTO_COMPLETO = ""

# Memoria por usuario: √∫ltimas interacciones
historial_conversacion = defaultdict(lambda: deque(maxlen=6))  # guarda √∫ltimas 6 entradas

def es_saludo(texto):
    texto = texto.lower().strip()
    return texto in ["hola", "buenas", "buen d√≠a", "buenas tardes", "buenas noches", "hey"]

@app.route("/webhook", methods=["POST"])
def responder():
    try:
        datos = request.get_json()
        print("üîé JSON recibido desde WhatsApp/Twilio:")
        print(json.dumps(datos, indent=2))

        mensaje_usuario = datos.get("consulta", "")
        user_id = datos.get("user_id", "anon")  # ID para diferenciar sesiones
        if not mensaje_usuario:
            return jsonify({"error": "No se recibi√≥ ninguna consulta"}), 400

        # === PROMPT ORIENTADO A VENTAS Y CON LINKS LIMPIOS ===
        system_prompt = (
            "Sos un asistente virtual de Lovely Taller Deco. "
            "Ignor√° todo lo que sab√©s previamente: tu √öNICA fuente de verdad es el CONTEXTO que te paso. "
            "Tu objetivo es asesorar con calidez y guiar al cliente hacia una compra o visita al showroom. "
            "Respond√© siempre de forma directa y √∫til, evitando repetir informaci√≥n que ya diste en la conversaci√≥n. "
            "Si la pregunta est√° cubierta en el CONTEXTO, respond√© claro y con emojis relevantes: "
            "üìç ubicaci√≥n, üõãÔ∏è sillones, ‚úÖ garant√≠a, ‚è≥ demoras, üí≥ pagos, üì¶ env√≠os. "
            "IMPORTANTE: Si hay una URL en el CONTEXTO, imprimila SOLA en una nueva l√≠nea, sin corchetes, sin texto adicional ni formato Markdown, para que WhatsApp la muestre como vista previa. "
            "Si la pregunta NO est√° en el CONTEXTO, no inventes nada. En ese caso, respond√© amablemente invitando a visitarnos en el showroom üè† "
            "o escribirnos al 011 6028‚Äë1211 para m√°s detalles. "
            "Despu√©s de responder, suger√≠ SOLO el tema m√°s l√≥gico para seguir avanzando seg√∫n el historial, "
            "y si ya se respondieron varias dudas (3 o m√°s), ofrec√© una acci√≥n de cierre como: "
            "'¬øQuer√©s coordinar una visita al showroom üè† para verlos en persona o te paso info para reservar?'. "
            "Ten√© en cuenta TODO el historial para evitar ser repetitivo."
        )

        # === ARMAMOS EL HISTORIAL DE CONVERSACI√ìN ===
        historial = list(historial_conversacion[user_id])  # √∫ltimas interacciones
        mensajes_historial = []

        for rol, msg in historial:
            mensajes_historial.append({"role": rol, "content": msg})

        # Nuevo mensaje del usuario
        mensajes_historial.append({"role": "user", "content": mensaje_usuario})

        # Construimos el input con CONTEXTO + HISTORIAL para dar continuidad
        user_prompt = (
            f"CONTEXTO:\n{CONTEXTO_COMPLETO}\n\n"
            "Ten√© en cuenta la conversaci√≥n anterior para entender a qu√© se refiere el usuario:\n\n"
        )

        for rol, msg in historial:
            user_prompt += f"{rol.upper()}: {msg}\n"

        user_prompt += f"\nUSUARIO (nuevo): {mensaje_usuario}"

        # === LLAMAMOS AL MODELO ===
        respuesta = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        )

        respuesta_llm = respuesta.choices[0].message.content.strip()

        # === GUARDAMOS EN HISTORIAL ===
        historial_conversacion[user_id].append(("user", mensaje_usuario))
        historial_conversacion[user_id].append(("bot", respuesta_llm))

        return jsonify({"respuesta": respuesta_llm})

    except Exception as e:
        print("üí• Error detectado:", e)
        return jsonify({"error": "Error interno en el servidor"}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
