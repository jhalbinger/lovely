from flask import Flask, request, jsonify
import openai
import os
from dotenv import load_dotenv
import json
from collections import defaultdict, deque

# === CONFIGURACIONES ===
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
project_id = os.getenv("OPENAI_PROJECT_ID")
organization_id = os.getenv("OPENAI_ORG_ID")

client = openai.OpenAI(
    api_key=api_key,
    project=project_id,
    organization=organization_id
)

app = Flask(__name__)

# === CARGAR TODO EL CONTEXTO UNA SOLA VEZ ===
txt_path = "lovely_taller.txt"
if os.path.exists(txt_path):
    with open(txt_path, "r", encoding="utf-8") as f:
        CONTEXTO_COMPLETO = f.read()
else:
    CONTEXTO_COMPLETO = ""

# Memoria por usuario: √∫ltimas interacciones
historial_conversacion = defaultdict(lambda: deque(maxlen=6))  # guarda √∫ltimas 6 entradas

def es_saludo(texto):
    texto = texto.lower().strip()
    return texto in ["hola", "buenas", "buen d√≠a", "buenas tardes", "buenas noches", "hey"]

@app.route("/webhook", methods=["POST"])
def responder():
    try:
        datos = request.get_json()
        print("üîé JSON recibido desde WhatsApp/Twilio:")
        print(json.dumps(datos, indent=2))

        mensaje_usuario = datos.get("consulta", "")
        user_id = datos.get("user_id", "anon")  # ID para diferenciar sesiones
        if not mensaje_usuario:
            return jsonify({"error": "No se recibi√≥ ninguna consulta"}), 400

        # === PROMPT CON ESTILO, NEGRITAS, EMOJIS Y SALTOS DE L√çNEA ===
        system_prompt = (
            "Sos un asistente virtual de **Lovely Taller Deco** üõãÔ∏è‚ú®. "
            "Ignor√° todo lo que sab√©s previamente: tu **√öNICA fuente de verdad es el CONTEXTO** que te paso. "
            "Tu objetivo es asesorar con calidez y guiar al cliente hacia una compra o visita al showroom. "
            "\n\n"
            "‚û°Ô∏è **Formato de respuesta:**\n"
            "- Us√° *negritas* para resaltar productos, precios, direcciones o datos importantes.\n"
            "- Separ√° ideas con **saltos de l√≠nea** para que sea f√°cil de leer en WhatsApp.\n"
            "- Us√° emojis para hacerlo m√°s visual: üìç ubicaci√≥n, üõãÔ∏è sillones, ‚úÖ garant√≠a, ‚è≥ demoras, üí≥ pagos, üì¶ env√≠os.\n"
            "- Si hay una URL en el CONTEXTO, imprimila **sola en una nueva l√≠nea**, sin corchetes ni texto adicional, para que WhatsApp la muestre como vista previa.\n"
            "\n"
            "‚û°Ô∏è **C√≥mo responder:**\n"
            "- Si la pregunta est√° cubierta en el CONTEXTO, respond√© **claro, directo y amable**.\n"
            "- Si la pregunta NO est√° en el CONTEXTO, **NO inventes nada**. En ese caso, invit√° a visitarnos en el showroom üè† "
            "o escribirnos al *011 6028‚Äë1211* para m√°s detalles.\n"
            "- Despu√©s de responder, suger√≠ **solo 1 tema l√≥gico para seguir avanzando**.\n"
            "- Si ya respondimos 3 o m√°s dudas, ofrec√© **acci√≥n de cierre** como:\n"
            "  *¬øQuer√©s coordinar una visita al showroom üè† para verlos en persona o te paso info para reservar?*\n"
            "- Ten√© en cuenta TODO el historial para **no repetir informaci√≥n ya dada**.\n"
        )

        # === ARMAMOS EL HISTORIAL DE CONVERSACI√ìN ===
        historial = list(historial_conversacion[user_id])  # √∫ltimas interacciones
        mensajes_historial = []

        for rol, msg in historial:
            mensajes_historial.append({"role": rol, "content": msg})

        # Nuevo mensaje del usuario
        mensajes_historial.append({"role": "user", "content": mensaje_usuario})

        # Construimos el input con CONTEXTO + HISTORIAL para dar continuidad
        user_prompt = (
            f"CONTEXTO:\n{CONTEXTO_COMPLETO}\n\n"
            "Ten√© en cuenta la conversaci√≥n anterior para entender a qu√© se refiere el usuario:\n\n"
        )

        for rol, msg in historial:
            user_prompt += f"{rol.upper()}: {msg}\n"

        user_prompt += f"\nUSUARIO (nuevo): {mensaje_usuario}"

        # === LLAMAMOS AL MODELO ===
        respuesta = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        )

        respuesta_llm = respuesta.choices[0].message.content.strip()

        # === GUARDAMOS EN HISTORIAL ===
        historial_conversacion[user_id].append(("user", mensaje_usuario))
        historial_conversacion[user_id].append(("bot", respuesta_llm))

        return jsonify({"respuesta": respuesta_llm})

    except Exception as e:
        print("üí• Error detectado:", e)
        return jsonify({"error": "Error interno en el servidor"}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
